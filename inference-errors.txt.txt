C:\inference-tester>run.bat --models "Llama-3.2-1B-Instruct,Qwen2.5-1.5B-Instruct" --quick --auto-download
2025-11-12 11:04:36 [    INFO] __main__: ============================================================
2025-11-12 11:04:36 [    INFO] __main__: LLM Inference Tester v0.1.0
2025-11-12 11:04:36 [    INFO] __main__: ============================================================
2025-11-12 11:04:37 [    INFO] __main__: Loading configuration...
2025-11-12 11:04:37 [    INFO] config_manager: Loading configuration from config.yaml
2025-11-12 11:04:37 [    INFO] config_manager: Loaded 6 model definitions
2025-11-12 11:04:37 [    INFO] __main__: Configuration loaded successfully
2025-11-12 11:04:37 [    INFO] __main__: Test mode: full
2025-11-12 11:04:37 [    INFO] __main__: Mode: Quick test (~1 hour)
2025-11-12 11:04:37 [    INFO] __main__: Scanning for models...
2025-11-12 11:04:37 [    INFO] model_manager: Scanning for models in models
2025-11-12 11:04:37 [    INFO] model_manager: Found 0 configured models locally
2025-11-12 11:04:37 [    INFO] __main__: Found 27 missing model files
2025-11-12 11:04:37 [    INFO] model_downloader: ============================================================
2025-11-12 11:04:37 [    INFO] model_downloader: Found 27 missing model files
2025-11-12 11:04:37 [    INFO] model_downloader: ============================================================
2025-11-12 11:04:37 [    INFO] model_downloader:   • Qwen2.5-1.5B-Instruct (Q2_K)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Qwen2.5-1.5B-Instruct (Q3_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Qwen2.5-1.5B-Instruct (Q4_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Qwen2.5-1.5B-Instruct (Q5_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Qwen2.5-1.5B-Instruct (Q6_K)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Qwen2.5-1.5B-Instruct (Q8_0)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Phi-3.5-mini-instruct (Q4_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Phi-3.5-mini-instruct (Q5_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Phi-3.5-mini-instruct (Q6_K)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Phi-3.5-mini-instruct (Q8_0)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-3.2-3B-Instruct (Q4_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-3.2-3B-Instruct (Q5_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-3.2-3B-Instruct (Q6_K)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-3.2-3B-Instruct (Q8_0)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-3.2-7B-Instruct (Q2_K)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-3.2-7B-Instruct (Q3_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-3.2-7B-Instruct (Q4_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-3.2-7B-Instruct (Q5_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-3.2-7B-Instruct (Q6_K)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-3.2-7B-Instruct (Q8_0)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Mistral-7B-Instruct-v0.3 (Q4_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Mistral-7B-Instruct-v0.3 (Q5_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Mistral-7B-Instruct-v0.3 (Q6_K)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Mistral-7B-Instruct-v0.3 (Q8_0)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-2-13B-Chat (Q3_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-2-13B-Chat (Q4_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:   • Llama-2-13B-Chat (Q5_K_M)
2025-11-12 11:04:37 [    INFO] model_downloader:
2025-11-12 11:04:37 [    INFO] model_downloader: These files will be downloaded from Hugging Face
2025-11-12 11:04:37 [    INFO] model_downloader: Estimated total download: 54-162 GB
2025-11-12 11:04:37 [    INFO] model_downloader: ============================================================
2025-11-12 11:04:37 [    INFO] model_downloader:
2025-11-12 11:04:37 [    INFO] model_downloader:
[1/27] Downloading Qwen2.5-1.5B-Instruct (Q2_K)...
2025-11-12 11:04:37 [    INFO] model_downloader: Downloading qwen2.5-1.5b-instruct-q2_k.gguf from Qwen/Qwen2.5-1.5B-Instruct-GGUF...
2025-11-12 11:04:37 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
C:\inference-tester\venv\Lib\site-packages\huggingface_hub\utils\_validators.py:186: UserWarning: The `resume_download` argument is deprecated and ignored in `hf_hub_download`. Downloads always resume whenever possible.
  warnings.warn(
C:\inference-tester\venv\Lib\site-packages\huggingface_hub\utils\_validators.py:202: UserWarning: The `local_dir_use_symlinks` argument is deprecated and ignored in `hf_hub_download`. Downloading to a local directory does not use symlinks anymore.
  warnings.warn(
2025-11-12 11:04:38 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q2_k.gguf "HTTP/1.1 302 Found"
2025-11-12 11:04:39 [    INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/Qwen/Qwen2.5-1.5B-Instruct-GGUF/xet-read-token/91cad51170dc346986eccefdc2dd33a9da36ead9 "HTTP/1.1 200 OK"
qwen2.5-1.5b-instruct-q2_k.gguf: 100%|██████████████████████████████████████████████| 753M/753M [00:12<00:00, 60.6MB/s]
2025-11-12 11:04:51 [    INFO] model_downloader: ✓ Successfully downloaded: qwen2.5-1.5b-instruct-q2_k.gguf
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 49: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 285, in main
    results = downloader.download_missing_models(
  File "C:\inference-tester\src\model_downloader.py", line 176, in download_missing_models
    success = self.download_model(
  File "C:\inference-tester\src\model_downloader.py", line 103, in download_model
    logger.info(f"✓ Successfully downloaded: {filename}")
Message: '✓ Successfully downloaded: qwen2.5-1.5b-instruct-q2_k.gguf'
Arguments: ()
2025-11-12 11:04:51 [    INFO] model_downloader:
[2/27] Downloading Qwen2.5-1.5B-Instruct (Q3_K_M)...
2025-11-12 11:04:51 [    INFO] model_downloader: Downloading qwen2.5-1.5b-instruct-q3_k_m.gguf from Qwen/Qwen2.5-1.5B-Instruct-GGUF...
2025-11-12 11:04:51 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:04:52 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q3_k_m.gguf "HTTP/1.1 302 Found"
2025-11-12 11:04:52 [    INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/Qwen/Qwen2.5-1.5B-Instruct-GGUF/xet-read-token/91cad51170dc346986eccefdc2dd33a9da36ead9 "HTTP/1.1 200 OK"
qwen2.5-1.5b-instruct-q3_k_m.gguf: 100%|████████████████████████████████████████████| 924M/924M [00:13<00:00, 66.3MB/s]
2025-11-12 11:05:06 [    INFO] model_downloader: ✓ Successfully downloaded: qwen2.5-1.5b-instruct-q3_k_m.gguf
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 49: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 285, in main
    results = downloader.download_missing_models(
  File "C:\inference-tester\src\model_downloader.py", line 176, in download_missing_models
    success = self.download_model(
  File "C:\inference-tester\src\model_downloader.py", line 103, in download_model
    logger.info(f"✓ Successfully downloaded: {filename}")
Message: '✓ Successfully downloaded: qwen2.5-1.5b-instruct-q3_k_m.gguf'
Arguments: ()
2025-11-12 11:05:06 [    INFO] model_downloader:
[3/27] Downloading Qwen2.5-1.5B-Instruct (Q4_K_M)...
2025-11-12 11:05:06 [    INFO] model_downloader: Downloading qwen2.5-1.5b-instruct-q4_k_m.gguf from Qwen/Qwen2.5-1.5B-Instruct-GGUF...
2025-11-12 11:05:06 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:05:06 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_k_m.gguf "HTTP/1.1 302 Found"
2025-11-12 11:05:06 [    INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/Qwen/Qwen2.5-1.5B-Instruct-GGUF/xet-read-token/91cad51170dc346986eccefdc2dd33a9da36ead9 "HTTP/1.1 200 OK"
qwen2.5-1.5b-instruct-q4_k_m.gguf: 100%|██████████████████████████████████████████| 1.12G/1.12G [00:16<00:00, 66.4MB/s]
2025-11-12 11:05:23 [    INFO] model_downloader: ✓ Successfully downloaded: qwen2.5-1.5b-instruct-q4_k_m.gguf
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 49: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 285, in main
    results = downloader.download_missing_models(
  File "C:\inference-tester\src\model_downloader.py", line 176, in download_missing_models
    success = self.download_model(
  File "C:\inference-tester\src\model_downloader.py", line 103, in download_model
    logger.info(f"✓ Successfully downloaded: {filename}")
Message: '✓ Successfully downloaded: qwen2.5-1.5b-instruct-q4_k_m.gguf'
Arguments: ()
2025-11-12 11:05:23 [    INFO] model_downloader:
[4/27] Downloading Qwen2.5-1.5B-Instruct (Q5_K_M)...
2025-11-12 11:05:23 [    INFO] model_downloader: Downloading qwen2.5-1.5b-instruct-q5_k_m.gguf from Qwen/Qwen2.5-1.5B-Instruct-GGUF...
2025-11-12 11:05:23 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:05:23 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q5_k_m.gguf "HTTP/1.1 302 Found"
2025-11-12 11:05:23 [    INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/Qwen/Qwen2.5-1.5B-Instruct-GGUF/xet-read-token/91cad51170dc346986eccefdc2dd33a9da36ead9 "HTTP/1.1 200 OK"
qwen2.5-1.5b-instruct-q5_k_m.gguf: 100%|██████████████████████████████████████████| 1.29G/1.29G [00:19<00:00, 66.5MB/s]
2025-11-12 11:05:42 [    INFO] model_downloader: ✓ Successfully downloaded: qwen2.5-1.5b-instruct-q5_k_m.gguf
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 49: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 285, in main
    results = downloader.download_missing_models(
  File "C:\inference-tester\src\model_downloader.py", line 176, in download_missing_models
    success = self.download_model(
  File "C:\inference-tester\src\model_downloader.py", line 103, in download_model
    logger.info(f"✓ Successfully downloaded: {filename}")
Message: '✓ Successfully downloaded: qwen2.5-1.5b-instruct-q5_k_m.gguf'
Arguments: ()
2025-11-12 11:05:42 [    INFO] model_downloader:
[5/27] Downloading Qwen2.5-1.5B-Instruct (Q6_K)...
2025-11-12 11:05:42 [    INFO] model_downloader: Downloading qwen2.5-1.5b-instruct-q6_k.gguf from Qwen/Qwen2.5-1.5B-Instruct-GGUF...
2025-11-12 11:05:42 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:05:42 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q6_k.gguf "HTTP/1.1 302 Found"
2025-11-12 11:05:42 [    INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/Qwen/Qwen2.5-1.5B-Instruct-GGUF/xet-read-token/91cad51170dc346986eccefdc2dd33a9da36ead9 "HTTP/1.1 200 OK"
qwen2.5-1.5b-instruct-q6_k.gguf: 100%|████████████████████████████████████████████| 1.46G/1.46G [00:20<00:00, 72.0MB/s]
2025-11-12 11:06:03 [    INFO] model_downloader: ✓ Successfully downloaded: qwen2.5-1.5b-instruct-q6_k.gguf
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 49: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 285, in main
    results = downloader.download_missing_models(
  File "C:\inference-tester\src\model_downloader.py", line 176, in download_missing_models
    success = self.download_model(
  File "C:\inference-tester\src\model_downloader.py", line 103, in download_model
    logger.info(f"✓ Successfully downloaded: {filename}")
Message: '✓ Successfully downloaded: qwen2.5-1.5b-instruct-q6_k.gguf'
Arguments: ()
2025-11-12 11:06:03 [    INFO] model_downloader:
[6/27] Downloading Qwen2.5-1.5B-Instruct (Q8_0)...
2025-11-12 11:06:03 [    INFO] model_downloader: Downloading qwen2.5-1.5b-instruct-q8_0.gguf from Qwen/Qwen2.5-1.5B-Instruct-GGUF...
2025-11-12 11:06:03 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:06:03 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q8_0.gguf "HTTP/1.1 302 Found"
2025-11-12 11:06:03 [    INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/Qwen/Qwen2.5-1.5B-Instruct-GGUF/xet-read-token/91cad51170dc346986eccefdc2dd33a9da36ead9 "HTTP/1.1 200 OK"
qwen2.5-1.5b-instruct-q8_0.gguf: 100%|████████████████████████████████████████████| 1.89G/1.89G [00:24<00:00, 77.0MB/s]
2025-11-12 11:06:27 [    INFO] model_downloader: ✓ Successfully downloaded: qwen2.5-1.5b-instruct-q8_0.gguf
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 49: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 285, in main
    results = downloader.download_missing_models(
  File "C:\inference-tester\src\model_downloader.py", line 176, in download_missing_models
    success = self.download_model(
  File "C:\inference-tester\src\model_downloader.py", line 103, in download_model
    logger.info(f"✓ Successfully downloaded: {filename}")
Message: '✓ Successfully downloaded: qwen2.5-1.5b-instruct-q8_0.gguf'
Arguments: ()
2025-11-12 11:06:27 [    INFO] model_downloader:
[7/27] Downloading Phi-3.5-mini-instruct (Q4_K_M)...
2025-11-12 11:06:27 [    INFO] model_downloader: Downloading Phi-3.5-mini-instruct-q4.gguf from microsoft/Phi-3.5-mini-instruct-gguf...
2025-11-12 11:06:27 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:06:27 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/microsoft/Phi-3.5-mini-instruct-gguf/resolve/main/Phi-3.5-mini-instruct-q4.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:06:27 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914dab5-523b3be738331aed139f7727;426622ad-e2b9-46a0-aa1f-0880c4373932)

Repository Not Found for url: https://huggingface.co/microsoft/Phi-3.5-mini-instruct-gguf/resolve/main/Phi-3.5-mini-instruct-q4.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:06:27 [ WARNING] model_downloader: Failed to download Phi-3.5-mini-instruct-q4.gguf
2025-11-12 11:06:27 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:06:27 [    INFO] model_downloader:
[8/27] Downloading Phi-3.5-mini-instruct (Q5_K_M)...
2025-11-12 11:06:27 [    INFO] model_downloader: Downloading Phi-3.5-mini-instruct-q5.gguf from microsoft/Phi-3.5-mini-instruct-gguf...
2025-11-12 11:06:27 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:06:28 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/microsoft/Phi-3.5-mini-instruct-gguf/resolve/main/Phi-3.5-mini-instruct-q5.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:06:28 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914dab5-62b04e6403fd904145eab82f;b6e6757b-24f5-404f-8973-7e5e067b151e)

Repository Not Found for url: https://huggingface.co/microsoft/Phi-3.5-mini-instruct-gguf/resolve/main/Phi-3.5-mini-instruct-q5.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:06:28 [ WARNING] model_downloader: Failed to download Phi-3.5-mini-instruct-q5.gguf
2025-11-12 11:06:28 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:06:28 [    INFO] model_downloader:
[9/27] Downloading Phi-3.5-mini-instruct (Q6_K)...
2025-11-12 11:06:28 [    INFO] model_downloader: Downloading Phi-3.5-mini-instruct-q6.gguf from microsoft/Phi-3.5-mini-instruct-gguf...
2025-11-12 11:06:28 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:06:28 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/microsoft/Phi-3.5-mini-instruct-gguf/resolve/main/Phi-3.5-mini-instruct-q6.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:06:28 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914dab5-26f576251f3f93987ae289a1;0ebbf396-9b2f-4766-9621-aaf4d457997b)

Repository Not Found for url: https://huggingface.co/microsoft/Phi-3.5-mini-instruct-gguf/resolve/main/Phi-3.5-mini-instruct-q6.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:06:28 [ WARNING] model_downloader: Failed to download Phi-3.5-mini-instruct-q6.gguf
2025-11-12 11:06:28 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:06:28 [    INFO] model_downloader:
[10/27] Downloading Phi-3.5-mini-instruct (Q8_0)...
2025-11-12 11:06:28 [    INFO] model_downloader: Downloading Phi-3.5-mini-instruct-q8.gguf from microsoft/Phi-3.5-mini-instruct-gguf...
2025-11-12 11:06:28 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:06:28 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/microsoft/Phi-3.5-mini-instruct-gguf/resolve/main/Phi-3.5-mini-instruct-q8.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:06:28 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914dab5-095e53e7041f5abf27319d7d;9e5c3d67-0e5c-46a5-9638-abd4be2c123e)

Repository Not Found for url: https://huggingface.co/microsoft/Phi-3.5-mini-instruct-gguf/resolve/main/Phi-3.5-mini-instruct-q8.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:06:28 [ WARNING] model_downloader: Failed to download Phi-3.5-mini-instruct-q8.gguf
2025-11-12 11:06:28 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:06:28 [    INFO] model_downloader:
[11/27] Downloading Llama-3.2-3B-Instruct (Q4_K_M)...
2025-11-12 11:06:28 [    INFO] model_downloader: Downloading Llama-3.2-3B-Instruct-Q4_K_M.gguf from lmstudio-community/Llama-3.2-3B-Instruct-GGUF...
2025-11-12 11:06:28 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:06:28 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/lmstudio-community/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf "HTTP/1.1 302 Found"
2025-11-12 11:06:28 [    INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/lmstudio-community/Llama-3.2-3B-Instruct-GGUF/xet-read-token/c91307b5cf18c8106b1f8a6218c26ae4dbfee472 "HTTP/1.1 200 OK"
Llama-3.2-3B-Instruct-Q4_K_M.gguf: 100%|██████████████████████████████████████████| 2.02G/2.02G [00:29<00:00, 68.4MB/s]
2025-11-12 11:06:57 [    INFO] model_downloader: ✓ Successfully downloaded: Llama-3.2-3B-Instruct-Q4_K_M.gguf
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 49: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 285, in main
    results = downloader.download_missing_models(
  File "C:\inference-tester\src\model_downloader.py", line 176, in download_missing_models
    success = self.download_model(
  File "C:\inference-tester\src\model_downloader.py", line 103, in download_model
    logger.info(f"✓ Successfully downloaded: {filename}")
Message: '✓ Successfully downloaded: Llama-3.2-3B-Instruct-Q4_K_M.gguf'
Arguments: ()
2025-11-12 11:06:57 [    INFO] model_downloader:
[12/27] Downloading Llama-3.2-3B-Instruct (Q5_K_M)...
2025-11-12 11:06:57 [    INFO] model_downloader: Downloading Llama-3.2-3B-Instruct-Q5_K_M.gguf from lmstudio-community/Llama-3.2-3B-Instruct-GGUF...
2025-11-12 11:06:57 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:06:57 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/lmstudio-community/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf "HTTP/1.1 404 Not Found"
2025-11-12 11:06:57 [   ERROR] model_downloader: Model file not found: lmstudio-community/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct-Q5_K_M.gguf
2025-11-12 11:06:57 [   ERROR] model_downloader: This file may have been renamed or removed from Hugging Face
2025-11-12 11:06:57 [ WARNING] model_downloader: Failed to download Llama-3.2-3B-Instruct-Q5_K_M.gguf
2025-11-12 11:06:57 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:06:57 [    INFO] model_downloader:
[13/27] Downloading Llama-3.2-3B-Instruct (Q6_K)...
2025-11-12 11:06:57 [    INFO] model_downloader: Downloading Llama-3.2-3B-Instruct-Q6_K.gguf from lmstudio-community/Llama-3.2-3B-Instruct-GGUF...
2025-11-12 11:06:57 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:06:57 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/lmstudio-community/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q6_K.gguf "HTTP/1.1 302 Found"
2025-11-12 11:06:58 [    INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/lmstudio-community/Llama-3.2-3B-Instruct-GGUF/xet-read-token/c91307b5cf18c8106b1f8a6218c26ae4dbfee472 "HTTP/1.1 200 OK"
Llama-3.2-3B-Instruct-Q6_K.gguf: 100%|████████████████████████████████████████████| 2.64G/2.64G [00:54<00:00, 48.4MB/s]
2025-11-12 11:07:52 [    INFO] model_downloader: ✓ Successfully downloaded: Llama-3.2-3B-Instruct-Q6_K.gguf
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 49: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 285, in main
    results = downloader.download_missing_models(
  File "C:\inference-tester\src\model_downloader.py", line 176, in download_missing_models
    success = self.download_model(
  File "C:\inference-tester\src\model_downloader.py", line 103, in download_model
    logger.info(f"✓ Successfully downloaded: {filename}")
Message: '✓ Successfully downloaded: Llama-3.2-3B-Instruct-Q6_K.gguf'
Arguments: ()
2025-11-12 11:07:52 [    INFO] model_downloader:
[14/27] Downloading Llama-3.2-3B-Instruct (Q8_0)...
2025-11-12 11:07:52 [    INFO] model_downloader: Downloading Llama-3.2-3B-Instruct-Q8_0.gguf from lmstudio-community/Llama-3.2-3B-Instruct-GGUF...
2025-11-12 11:07:52 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:07:52 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/lmstudio-community/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q8_0.gguf "HTTP/1.1 302 Found"
2025-11-12 11:07:52 [    INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/lmstudio-community/Llama-3.2-3B-Instruct-GGUF/xet-read-token/c91307b5cf18c8106b1f8a6218c26ae4dbfee472 "HTTP/1.1 200 OK"
Llama-3.2-3B-Instruct-Q8_0.gguf: 100%|████████████████████████████████████████████| 3.42G/3.42G [00:47<00:00, 72.4MB/s]
2025-11-12 11:08:40 [    INFO] model_downloader: ✓ Successfully downloaded: Llama-3.2-3B-Instruct-Q8_0.gguf
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 49: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 285, in main
    results = downloader.download_missing_models(
  File "C:\inference-tester\src\model_downloader.py", line 176, in download_missing_models
    success = self.download_model(
  File "C:\inference-tester\src\model_downloader.py", line 103, in download_model
    logger.info(f"✓ Successfully downloaded: {filename}")
Message: '✓ Successfully downloaded: Llama-3.2-3B-Instruct-Q8_0.gguf'
Arguments: ()
2025-11-12 11:08:40 [    INFO] model_downloader:
[15/27] Downloading Llama-3.2-7B-Instruct (Q2_K)...
2025-11-12 11:08:40 [    INFO] model_downloader: Downloading Llama-3.2-7B-Instruct-Q2_K.gguf from lmstudio-community/Llama-3.2-7B-Instruct-GGUF...
2025-11-12 11:08:40 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/lmstudio-community/Llama-3.2-7B-Instruct-GGUF/resolve/main/Llama-3.2-7B-Instruct-Q2_K.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:08:40 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914db3a-2e0e24355e1b64a52a61eac5;10e5b524-81aa-4122-96cc-b9c5c3dd5b21)

Repository Not Found for url: https://huggingface.co/lmstudio-community/Llama-3.2-7B-Instruct-GGUF/resolve/main/Llama-3.2-7B-Instruct-Q2_K.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:08:40 [ WARNING] model_downloader: Failed to download Llama-3.2-7B-Instruct-Q2_K.gguf
2025-11-12 11:08:40 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:08:40 [    INFO] model_downloader:
[16/27] Downloading Llama-3.2-7B-Instruct (Q3_K_M)...
2025-11-12 11:08:40 [    INFO] model_downloader: Downloading Llama-3.2-7B-Instruct-Q3_K_M.gguf from lmstudio-community/Llama-3.2-7B-Instruct-GGUF...
2025-11-12 11:08:40 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/lmstudio-community/Llama-3.2-7B-Instruct-GGUF/resolve/main/Llama-3.2-7B-Instruct-Q3_K_M.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:08:40 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914db3a-3b2b458e5dad682f60825b4c;79d33875-301a-4753-8baa-3f695107b92f)

Repository Not Found for url: https://huggingface.co/lmstudio-community/Llama-3.2-7B-Instruct-GGUF/resolve/main/Llama-3.2-7B-Instruct-Q3_K_M.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:08:40 [ WARNING] model_downloader: Failed to download Llama-3.2-7B-Instruct-Q3_K_M.gguf
2025-11-12 11:08:40 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:08:40 [    INFO] model_downloader:
[17/27] Downloading Llama-3.2-7B-Instruct (Q4_K_M)...
2025-11-12 11:08:40 [    INFO] model_downloader: Downloading Llama-3.2-7B-Instruct-Q4_K_M.gguf from lmstudio-community/Llama-3.2-7B-Instruct-GGUF...
2025-11-12 11:08:40 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/lmstudio-community/Llama-3.2-7B-Instruct-GGUF/resolve/main/Llama-3.2-7B-Instruct-Q4_K_M.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:08:40 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914db3a-3691737d7c2ac2b914bb28ac;88ef5594-b38b-460e-8680-10ee917a45dc)

Repository Not Found for url: https://huggingface.co/lmstudio-community/Llama-3.2-7B-Instruct-GGUF/resolve/main/Llama-3.2-7B-Instruct-Q4_K_M.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:08:40 [ WARNING] model_downloader: Failed to download Llama-3.2-7B-Instruct-Q4_K_M.gguf
2025-11-12 11:08:40 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:08:40 [    INFO] model_downloader:
[18/27] Downloading Llama-3.2-7B-Instruct (Q5_K_M)...
2025-11-12 11:08:40 [    INFO] model_downloader: Downloading Llama-3.2-7B-Instruct-Q5_K_M.gguf from lmstudio-community/Llama-3.2-7B-Instruct-GGUF...
2025-11-12 11:08:40 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/lmstudio-community/Llama-3.2-7B-Instruct-GGUF/resolve/main/Llama-3.2-7B-Instruct-Q5_K_M.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:08:40 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914db3a-3b3cff910b5c7d1f25d01376;da0c133e-aea4-448f-b113-3fad11ee2cfe)

Repository Not Found for url: https://huggingface.co/lmstudio-community/Llama-3.2-7B-Instruct-GGUF/resolve/main/Llama-3.2-7B-Instruct-Q5_K_M.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:08:40 [ WARNING] model_downloader: Failed to download Llama-3.2-7B-Instruct-Q5_K_M.gguf
2025-11-12 11:08:40 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:08:40 [    INFO] model_downloader:
[19/27] Downloading Llama-3.2-7B-Instruct (Q6_K)...
2025-11-12 11:08:40 [    INFO] model_downloader: Downloading Llama-3.2-7B-Instruct-Q6_K.gguf from lmstudio-community/Llama-3.2-7B-Instruct-GGUF...
2025-11-12 11:08:40 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/lmstudio-community/Llama-3.2-7B-Instruct-GGUF/resolve/main/Llama-3.2-7B-Instruct-Q6_K.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:08:40 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914db3a-6e3cbf325d2345a04c854d86;edaf3b42-f995-4298-abcc-326c21be736a)

Repository Not Found for url: https://huggingface.co/lmstudio-community/Llama-3.2-7B-Instruct-GGUF/resolve/main/Llama-3.2-7B-Instruct-Q6_K.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:08:40 [ WARNING] model_downloader: Failed to download Llama-3.2-7B-Instruct-Q6_K.gguf
2025-11-12 11:08:40 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:08:40 [    INFO] model_downloader:
[20/27] Downloading Llama-3.2-7B-Instruct (Q8_0)...
2025-11-12 11:08:40 [    INFO] model_downloader: Downloading Llama-3.2-7B-Instruct-Q8_0.gguf from lmstudio-community/Llama-3.2-7B-Instruct-GGUF...
2025-11-12 11:08:40 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/lmstudio-community/Llama-3.2-7B-Instruct-GGUF/resolve/main/Llama-3.2-7B-Instruct-Q8_0.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:08:40 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914db3a-54d064bf0ae89d2644a29eb4;82c64ad0-fb74-469c-8df3-519d9fe1b704)

Repository Not Found for url: https://huggingface.co/lmstudio-community/Llama-3.2-7B-Instruct-GGUF/resolve/main/Llama-3.2-7B-Instruct-Q8_0.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:08:40 [ WARNING] model_downloader: Failed to download Llama-3.2-7B-Instruct-Q8_0.gguf
2025-11-12 11:08:40 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:08:40 [    INFO] model_downloader:
[21/27] Downloading Mistral-7B-Instruct-v0.3 (Q4_K_M)...
2025-11-12 11:08:40 [    INFO] model_downloader: Downloading mistral-7b-instruct-v0.3.Q4_K_M.gguf from TheBloke/Mistral-7B-Instruct-v0.3-GGUF...
2025-11-12 11:08:40 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/mistral-7b-instruct-v0.3.Q4_K_M.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:08:40 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914db3a-4a1796d06c348040612396bd;fa00d7a0-d0bc-4257-bd16-d1359b4d995a)

Repository Not Found for url: https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/mistral-7b-instruct-v0.3.Q4_K_M.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:08:40 [ WARNING] model_downloader: Failed to download mistral-7b-instruct-v0.3.Q4_K_M.gguf
2025-11-12 11:08:40 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:08:40 [    INFO] model_downloader:
[22/27] Downloading Mistral-7B-Instruct-v0.3 (Q5_K_M)...
2025-11-12 11:08:40 [    INFO] model_downloader: Downloading mistral-7b-instruct-v0.3.Q5_K_M.gguf from TheBloke/Mistral-7B-Instruct-v0.3-GGUF...
2025-11-12 11:08:40 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/mistral-7b-instruct-v0.3.Q5_K_M.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:08:40 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914db3a-6c1a3fab6487467a4f30933d;170f9cd9-33ba-46af-beba-6e7ee6549ade)

Repository Not Found for url: https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/mistral-7b-instruct-v0.3.Q5_K_M.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:08:40 [ WARNING] model_downloader: Failed to download mistral-7b-instruct-v0.3.Q5_K_M.gguf
2025-11-12 11:08:40 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:08:40 [    INFO] model_downloader:
[23/27] Downloading Mistral-7B-Instruct-v0.3 (Q6_K)...
2025-11-12 11:08:40 [    INFO] model_downloader: Downloading mistral-7b-instruct-v0.3.Q6_K.gguf from TheBloke/Mistral-7B-Instruct-v0.3-GGUF...
2025-11-12 11:08:40 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/mistral-7b-instruct-v0.3.Q6_K.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:08:40 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914db3a-02734d85739acbb639f0f990;38427bd1-1f2e-46f2-b216-0bf5d22f1978)

Repository Not Found for url: https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/mistral-7b-instruct-v0.3.Q6_K.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:08:40 [ WARNING] model_downloader: Failed to download mistral-7b-instruct-v0.3.Q6_K.gguf
2025-11-12 11:08:40 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:08:40 [    INFO] model_downloader:
[24/27] Downloading Mistral-7B-Instruct-v0.3 (Q8_0)...
2025-11-12 11:08:40 [    INFO] model_downloader: Downloading mistral-7b-instruct-v0.3.Q8_0.gguf from TheBloke/Mistral-7B-Instruct-v0.3-GGUF...
2025-11-12 11:08:40 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/mistral-7b-instruct-v0.3.Q8_0.gguf "HTTP/1.1 401 Unauthorized"
2025-11-12 11:08:40 [   ERROR] model_downloader: HTTP error downloading model: 401 Client Error. (Request ID: Root=1-6914db3a-2b969e8b04bfc27e1e602ee1;27e7aebd-b0b8-4b43-8127-f7ba2542212a)

Repository Not Found for url: https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/mistral-7b-instruct-v0.3.Q8_0.gguf.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.
2025-11-12 11:08:40 [ WARNING] model_downloader: Failed to download mistral-7b-instruct-v0.3.Q8_0.gguf
2025-11-12 11:08:40 [ WARNING] model_downloader: Tests using this model will be skipped
2025-11-12 11:08:40 [    INFO] model_downloader:
[25/27] Downloading Llama-2-13B-Chat (Q3_K_M)...
2025-11-12 11:08:40 [    INFO] model_downloader: Downloading llama-2-13b-chat.Q3_K_M.gguf from TheBloke/Llama-2-13B-Chat-GGUF...
2025-11-12 11:08:40 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/TheBloke/Llama-2-13B-Chat-GGUF/resolve/main/llama-2-13b-chat.Q3_K_M.gguf "HTTP/1.1 307 Temporary Redirect"
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q3_K_M.gguf "HTTP/1.1 302 Found"
2025-11-12 11:08:40 [    INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/TheBloke/Llama-2-13B-chat-GGUF/xet-read-token/4458acc949de0a9914c3eab623904d4fe999050a "HTTP/1.1 200 OK"
llama-2-13b-chat.Q3_K_M.gguf: 100%|███████████████████████████████████████████████| 6.34G/6.34G [01:47<00:00, 58.9MB/s]
2025-11-12 11:10:28 [    INFO] model_downloader: ✓ Successfully downloaded: llama-2-13b-chat.Q3_K_M.gguf
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 49: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 285, in main
    results = downloader.download_missing_models(
  File "C:\inference-tester\src\model_downloader.py", line 176, in download_missing_models
    success = self.download_model(
  File "C:\inference-tester\src\model_downloader.py", line 103, in download_model
    logger.info(f"✓ Successfully downloaded: {filename}")
Message: '✓ Successfully downloaded: llama-2-13b-chat.Q3_K_M.gguf'
Arguments: ()
2025-11-12 11:10:28 [    INFO] model_downloader:
[26/27] Downloading Llama-2-13B-Chat (Q4_K_M)...
2025-11-12 11:10:28 [    INFO] model_downloader: Downloading llama-2-13b-chat.Q4_K_M.gguf from TheBloke/Llama-2-13B-Chat-GGUF...
2025-11-12 11:10:28 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:10:28 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/TheBloke/Llama-2-13B-Chat-GGUF/resolve/main/llama-2-13b-chat.Q4_K_M.gguf "HTTP/1.1 307 Temporary Redirect"
2025-11-12 11:10:28 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q4_K_M.gguf "HTTP/1.1 302 Found"
2025-11-12 11:10:28 [    INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/TheBloke/Llama-2-13B-chat-GGUF/xet-read-token/4458acc949de0a9914c3eab623904d4fe999050a "HTTP/1.1 200 OK"
llama-2-13b-chat.Q4_K_M.gguf: 100%|███████████████████████████████████████████████| 7.87G/7.87G [02:04<00:00, 63.3MB/s]
2025-11-12 11:12:32 [    INFO] model_downloader: ✓ Successfully downloaded: llama-2-13b-chat.Q4_K_M.gguf
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 49: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 285, in main
    results = downloader.download_missing_models(
  File "C:\inference-tester\src\model_downloader.py", line 176, in download_missing_models
    success = self.download_model(
  File "C:\inference-tester\src\model_downloader.py", line 103, in download_model
    logger.info(f"✓ Successfully downloaded: {filename}")
Message: '✓ Successfully downloaded: llama-2-13b-chat.Q4_K_M.gguf'
Arguments: ()
2025-11-12 11:12:32 [    INFO] model_downloader:
[27/27] Downloading Llama-2-13B-Chat (Q5_K_M)...
2025-11-12 11:12:32 [    INFO] model_downloader: Downloading llama-2-13b-chat.Q5_K_M.gguf from TheBloke/Llama-2-13B-Chat-GGUF...
2025-11-12 11:12:32 [    INFO] model_downloader: This may take several minutes depending on file size and connection speed.
2025-11-12 11:12:33 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/TheBloke/Llama-2-13B-Chat-GGUF/resolve/main/llama-2-13b-chat.Q5_K_M.gguf "HTTP/1.1 307 Temporary Redirect"
2025-11-12 11:12:33 [    INFO] httpx: HTTP Request: HEAD https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q5_K_M.gguf "HTTP/1.1 302 Found"
2025-11-12 11:12:33 [    INFO] httpx: HTTP Request: GET https://huggingface.co/api/models/TheBloke/Llama-2-13B-chat-GGUF/xet-read-token/4458acc949de0a9914c3eab623904d4fe999050a "HTTP/1.1 200 OK"
llama-2-13b-chat.Q5_K_M.gguf: 100%|███████████████████████████████████████████████| 9.23G/9.23G [02:27<00:00, 62.5MB/s]
2025-11-12 11:15:00 [    INFO] model_downloader: ✓ Successfully downloaded: llama-2-13b-chat.Q5_K_M.gguf
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 49: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 285, in main
    results = downloader.download_missing_models(
  File "C:\inference-tester\src\model_downloader.py", line 176, in download_missing_models
    success = self.download_model(
  File "C:\inference-tester\src\model_downloader.py", line 103, in download_model
    logger.info(f"✓ Successfully downloaded: {filename}")
Message: '✓ Successfully downloaded: llama-2-13b-chat.Q5_K_M.gguf'
Arguments: ()
2025-11-12 11:15:00 [    INFO] model_downloader:
2025-11-12 11:15:00 [    INFO] model_downloader: ============================================================
2025-11-12 11:15:00 [    INFO] model_downloader: Download Summary
2025-11-12 11:15:00 [    INFO] model_downloader: ============================================================
2025-11-12 11:15:00 [    INFO] model_downloader: Successful: 12
2025-11-12 11:15:00 [    INFO] model_downloader: Failed: 15
2025-11-12 11:15:00 [    INFO] model_downloader: ============================================================
2025-11-12 11:15:00 [    INFO] __main__: Rescanning models after downloads...
2025-11-12 11:15:00 [    INFO] model_manager: Scanning for models in models
2025-11-12 11:15:00 [    INFO] model_manager: Found 12 configured models locally
2025-11-12 11:15:00 [    INFO] __main__: ============================================================
2025-11-12 11:15:00 [    INFO] __main__: Starting Matrix Test Run
2025-11-12 11:15:00 [    INFO] __main__: ============================================================
2025-11-12 11:15:01 [    INFO] matrix_runner: Starting matrix test run
2025-11-12 11:15:01 [    INFO] matrix_runner: Generated 8 test configurations
2025-11-12 11:15:01 [    INFO] matrix_runner:
=== Test 1/8: Qwen2.5-1.5B-Instruct Q4_K_M - interactive ===
2025-11-12 11:15:01 [    INFO] matrix_runner: Ensuring model Qwen2.5-1.5B-Instruct (Q4_K_M) is available...
2025-11-12 11:15:01 [    INFO] matrix_runner: Starting llama.cpp server (ctx_size=4096)...
2025-11-12 11:15:01 [   ERROR] matrix_runner: Test failed: ServerManager.start() got an unexpected keyword argument 'timeout'
Traceback (most recent call last):
  File "C:\inference-tester\src\matrix_runner.py", line 380, in _execute_test
    connection = self.server_mgr.start(
                 ^^^^^^^^^^^^^^^^^^^^^^
TypeError: ServerManager.start() got an unexpected keyword argument 'timeout'
2025-11-12 11:15:01 [    INFO] matrix_runner:
=== Test 2/8: Qwen2.5-1.5B-Instruct Q4_K_M - long_context ===
2025-11-12 11:15:01 [    INFO] matrix_runner: Ensuring model Qwen2.5-1.5B-Instruct (Q4_K_M) is available...
2025-11-12 11:15:01 [    INFO] matrix_runner: Starting llama.cpp server (ctx_size=65536)...
2025-11-12 11:15:01 [   ERROR] matrix_runner: Test failed: ServerManager.start() got an unexpected keyword argument 'timeout'
Traceback (most recent call last):
  File "C:\inference-tester\src\matrix_runner.py", line 380, in _execute_test
    connection = self.server_mgr.start(
                 ^^^^^^^^^^^^^^^^^^^^^^
TypeError: ServerManager.start() got an unexpected keyword argument 'timeout'
2025-11-12 11:15:01 [    INFO] matrix_runner:
=== Test 3/8: Qwen2.5-1.5B-Instruct Q4_K_M - batch ===
2025-11-12 11:15:01 [    INFO] matrix_runner: Ensuring model Qwen2.5-1.5B-Instruct (Q4_K_M) is available...
2025-11-12 11:15:01 [    INFO] matrix_runner: Starting llama.cpp server (ctx_size=4096)...
2025-11-12 11:15:01 [   ERROR] matrix_runner: Test failed: ServerManager.start() got an unexpected keyword argument 'timeout'
Traceback (most recent call last):
  File "C:\inference-tester\src\matrix_runner.py", line 380, in _execute_test
    connection = self.server_mgr.start(
                 ^^^^^^^^^^^^^^^^^^^^^^
TypeError: ServerManager.start() got an unexpected keyword argument 'timeout'
2025-11-12 11:15:01 [    INFO] matrix_runner:
=== Test 4/8: Qwen2.5-1.5B-Instruct Q4_K_M - quality ===
2025-11-12 11:15:01 [    INFO] matrix_runner: Ensuring model Qwen2.5-1.5B-Instruct (Q4_K_M) is available...
2025-11-12 11:15:01 [    INFO] matrix_runner: Starting llama.cpp server (ctx_size=8192)...
2025-11-12 11:15:01 [   ERROR] matrix_runner: Test failed: ServerManager.start() got an unexpected keyword argument 'timeout'
Traceback (most recent call last):
  File "C:\inference-tester\src\matrix_runner.py", line 380, in _execute_test
    connection = self.server_mgr.start(
                 ^^^^^^^^^^^^^^^^^^^^^^
TypeError: ServerManager.start() got an unexpected keyword argument 'timeout'
2025-11-12 11:15:01 [    INFO] matrix_runner:
=== Test 5/8: Qwen2.5-1.5B-Instruct Q5_K_M - interactive ===
2025-11-12 11:15:01 [    INFO] matrix_runner: Ensuring model Qwen2.5-1.5B-Instruct (Q5_K_M) is available...
2025-11-12 11:15:01 [    INFO] matrix_runner: Starting llama.cpp server (ctx_size=4096)...
2025-11-12 11:15:01 [   ERROR] matrix_runner: Test failed: ServerManager.start() got an unexpected keyword argument 'timeout'
Traceback (most recent call last):
  File "C:\inference-tester\src\matrix_runner.py", line 380, in _execute_test
    connection = self.server_mgr.start(
                 ^^^^^^^^^^^^^^^^^^^^^^
TypeError: ServerManager.start() got an unexpected keyword argument 'timeout'
2025-11-12 11:15:01 [    INFO] matrix_runner:
=== Test 6/8: Qwen2.5-1.5B-Instruct Q5_K_M - long_context ===
2025-11-12 11:15:01 [    INFO] matrix_runner: Ensuring model Qwen2.5-1.5B-Instruct (Q5_K_M) is available...
2025-11-12 11:15:01 [    INFO] matrix_runner: Starting llama.cpp server (ctx_size=65536)...
2025-11-12 11:15:01 [   ERROR] matrix_runner: Test failed: ServerManager.start() got an unexpected keyword argument 'timeout'
Traceback (most recent call last):
  File "C:\inference-tester\src\matrix_runner.py", line 380, in _execute_test
    connection = self.server_mgr.start(
                 ^^^^^^^^^^^^^^^^^^^^^^
TypeError: ServerManager.start() got an unexpected keyword argument 'timeout'
2025-11-12 11:15:01 [    INFO] matrix_runner:
=== Test 7/8: Qwen2.5-1.5B-Instruct Q5_K_M - batch ===
2025-11-12 11:15:01 [    INFO] matrix_runner: Ensuring model Qwen2.5-1.5B-Instruct (Q5_K_M) is available...
2025-11-12 11:15:01 [    INFO] matrix_runner: Starting llama.cpp server (ctx_size=4096)...
2025-11-12 11:15:01 [   ERROR] matrix_runner: Test failed: ServerManager.start() got an unexpected keyword argument 'timeout'
Traceback (most recent call last):
  File "C:\inference-tester\src\matrix_runner.py", line 380, in _execute_test
    connection = self.server_mgr.start(
                 ^^^^^^^^^^^^^^^^^^^^^^
TypeError: ServerManager.start() got an unexpected keyword argument 'timeout'
2025-11-12 11:15:01 [    INFO] matrix_runner:
=== Test 8/8: Qwen2.5-1.5B-Instruct Q5_K_M - quality ===
2025-11-12 11:15:01 [    INFO] matrix_runner: Ensuring model Qwen2.5-1.5B-Instruct (Q5_K_M) is available...
2025-11-12 11:15:01 [    INFO] matrix_runner: Starting llama.cpp server (ctx_size=8192)...
2025-11-12 11:15:01 [   ERROR] matrix_runner: Test failed: ServerManager.start() got an unexpected keyword argument 'timeout'
Traceback (most recent call last):
  File "C:\inference-tester\src\matrix_runner.py", line 380, in _execute_test
    connection = self.server_mgr.start(
                 ^^^^^^^^^^^^^^^^^^^^^^
TypeError: ServerManager.start() got an unexpected keyword argument 'timeout'
2025-11-12 11:15:01 [    INFO] matrix_runner:
=== Matrix testing complete ===
2025-11-12 11:15:01 [    INFO] matrix_runner: Total tests: 8
2025-11-12 11:15:01 [    INFO] matrix_runner: Passed: 0
2025-11-12 11:15:01 [    INFO] matrix_runner: Failed: 8
2025-11-12 11:15:01 [    INFO] __main__:
============================================================
2025-11-12 11:15:01 [    INFO] __main__: MATRIX TEST RESULTS
2025-11-12 11:15:01 [    INFO] __main__: ============================================================
2025-11-12 11:15:01 [    INFO] __main__: Total tests: 8
2025-11-12 11:15:01 [    INFO] __main__: Passed: 0
2025-11-12 11:15:01 [    INFO] __main__: Failed: 8
2025-11-12 11:15:01 [    INFO] __main__: Skipped: 0
2025-11-12 11:15:01 [    INFO] __main__:
2025-11-12 11:15:01 [    INFO] __main__: Results by status:
2025-11-12 11:15:01 [    INFO] __main__:   error: 8
2025-11-12 11:15:01 [    INFO] __main__:
============================================================
2025-11-12 11:15:01 [    INFO] __main__: Generating Reports
2025-11-12 11:15:01 [    INFO] __main__: ============================================================
2025-11-12 11:15:01 [    INFO] __main__: Generating recommendations...
2025-11-12 11:15:01 [    INFO] __main__: Saving JSON results...
2025-11-12 11:15:01 [    INFO] __main__:   ✓ JSON: results\results.json
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 43: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 406, in main
    logger.info(f"  ✓ JSON: {results_file}")
Message: '  ✓ JSON: results\\results.json'
Arguments: ()
2025-11-12 11:15:01 [    INFO] __main__: Saving CSV results...
2025-11-12 11:15:01 [    INFO] reports.csv_formatter: Writing results to CSV: results\results.csv
2025-11-12 11:15:01 [    INFO] reports.csv_formatter: CSV export complete: 8 rows written
2025-11-12 11:15:01 [    INFO] __main__:   ✓ CSV: results\results.csv
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 43: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 412, in main
    logger.info(f"  ✓ CSV: {csv_file}")
Message: '  ✓ CSV: results\\results.csv'
Arguments: ()
2025-11-12 11:15:01 [    INFO] reports.csv_formatter: Writing summary to CSV: results\summary.csv
2025-11-12 11:15:01 [    INFO] reports.csv_formatter: Summary CSV export complete
2025-11-12 11:15:01 [    INFO] __main__:   ✓ Summary CSV: results\summary.csv
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1113, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 43: character maps to <undefined>
Call stack:
  File "C:\inference-tester\src\main.py", line 459, in <module>
    sys.exit(main())
  File "C:\inference-tester\src\main.py", line 417, in main
    logger.info(f"  ✓ Summary CSV: {summary_csv}")
Message: '  ✓ Summary CSV: results\\summary.csv'
Arguments: ()
2025-11-12 11:15:01 [    INFO] __main__: Generating HTML report...
2025-11-12 11:15:01 [    INFO] reports.html_generator: Generating HTML report: results\report.html
2025-11-12 11:15:01 [   ERROR] __main__: Unexpected error: 'charmap' codec can't encode character '\u2192' in position 3028: character maps to <undefined>
Traceback (most recent call last):
  File "C:\inference-tester\src\main.py", line 428, in main
    HTMLGenerator.generate_report(test_runs_dict, summary, recommendations, html_file)
  File "C:\inference-tester\src\reports\html_generator.py", line 40, in generate_report
    f.write(html)
  File "C:\Users\BSMiniOne\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'charmap' codec can't encode character '\u2192' in position 3028: character maps to <undefined>

(venv) C:\inference-tester>